output: default
groups: {}
asyncFuncTimeout: 1000
functions:
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: |-
        Assign the log field to _raw
        Preserve the docker processed time as microservices_time
        Preserve the stream field (stderr, stdout)
  - id: regex_extract
    filter: "true"
    disabled: false
    conf:
      source: _raw
      iterations: 100
      overwrite: false
      regex: /"(log|line|msg|message)":\s*"(?<_raw>([\s\S]*?))(",\s*"|"}$)/gm
      regexList:
        - regex: /"(?<_NAME_0>[^"]+)":\s*"(?<_VALUE_0>[^"]+(?<!",|"}))/g
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: >-
        Slice the 2nd line to last line, create ONE field joined with a new
        line, 

        rather than keeping the lines as part of an array. This will allow us to have ONE pipeline to process these logs regardless if they originated from containers or not.


        What happens if we don't do join and want the first to third lines?
  - id: eval
    filter: "true"
    disabled: false
    conf:
      add:
        - name: _raw
          value: _raw.slice(1).join('\n')
        - name: multiline
          value: "_raw.match('\\n.*\\n') ? true : false"
      remove:
        - log
        - line
        - message
        - msg
      keep: []
    description: Redefine _raw as a single line with carriage returns. This will make the
      logs the same as if they came from a non-containerized environment
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: >-
        Address non _raw field multi-value arrays. Preserve the first entry
        only.

        NOTE: repeat this for every other non _raw field in your data
  - id: eval
    filter: multiline==true
    disabled: null
    conf:
      add:
        - name: stream
          value: stream[0]
        - name: time
          value: time[0]
    description: Address non _raw field multi-value arrays. Preserve the first entry only.
